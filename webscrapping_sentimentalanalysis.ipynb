import requests
for i in range(1,11):
    print("page:",i)
    url=f'https://quotes.toscrape.com/page/{i}/'
    r=requests.get(url)#to extract the info from website to r
    #print(r.status_code)#to check the status of the process few eg of http status code is 404 error it is used to server is responding to request  or not
    #print(r.text)#to print the content of the website in text format
    html=r.text
    with open('quotes.txt','a',encoding='utf-8') as f:
     for line in html.split('\n'):
        if'<span class="text" itemprop="text">' in line:

         line=line.replace('<span class="text" itemprop="text">“','').replace('”</span>','')
         line=line.strip()#removing whote spaces at the end of the lines
         f.write(line)
         f.write("\n")

   # with open('authors.txt','a',encoding='utf-8') as g:
    #for line in html.split('\n'):
      #  if'<span>by <small class="author" itemprop="author">' in line:

       # line=line.replace(' <span>by <small class="author" itemprop="author">','').replace('</small>','')
       # line=line.strip()#removing whote spaces at the end of the lines
       # g.write(line)
       #
       # g.write("\n")
import nltk
nltk.download('vader_lexicon')
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    """
    Analyzes the sentiment of the given text using NLTK's VADER sentiment analyzer.
    Returns a dictionary containing sentiment scores.
    """
    sentiment_scores = sid.polarity_scores(text)
    return sentiment_scores

def main():
    # Read quotes from the text file
    with open('quotes.txt', 'r') as file:
        quotes = file.readlines()

    # Analyze sentiment for each quote
    for idx, quote in enumerate(quotes, start=1):
        # Remove leading/trailing whitespaces
        quote = quote.strip()
        # Skip empty lines
        if not quote:
            continue

        # Analyze sentiment
        sentiment_scores = analyze_sentiment(quote)

        print(f"Quote {idx}: {quote}")
        print("Sentiment Scores:", sentiment_scores)
        print()


import matplotlib.pyplot as plt

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    """
    Analyzes the sentiment of the given text using NLTK's VADER sentiment analyzer.
    Returns a dictionary containing sentiment scores.
    """
    sentiment_scores = sid.polarity_scores(text)
    return sentiment_scores

def plot_sentiment_distribution(sentiment_scores):
    """
    Plots the sentiment distribution for the given sentiment scores.
    """
    labels = list(sentiment_scores.keys())
    values = list(sentiment_scores.values())

    plt.figure(figsize=(8, 6))
    plt.bar(labels, values, color=['green', 'red', 'blue', 'orange'])
    plt.xlabel('Sentiment')
    plt.ylabel('Frequency')
    plt.title('Sentiment Distribution')
    plt.show()

def main():
    # Read quotes from the text file
    with open('quotes.txt', 'r') as file:
        quotes = file.readlines()

    # Analyze sentiment for each quote
    sentiment_scores = {'pos': 0, 'neg': 0, 'neu': 0, 'compound': 0}
    for quote in quotes:
        # Remove leading/trailing whitespaces
        quote = quote.strip()
        # Skip empty lines
        if not quote:
            continue

        # Analyze sentiment
        scores = analyze_sentiment(quote)
        sentiment_scores['pos'] += scores['pos']
        sentiment_scores['neg'] += scores['neg']
        sentiment_scores['neu'] += scores['neu']
        sentiment_scores['compound'] += scores['compound']

    # Normalize compound score to fit into the [0, 1] range
    sentiment_scores['compound'] /= len(quotes)

    print("Sentiment Scores:", sentiment_scores)

    # Plot sentiment distribution
    plot_sentiment_distribution(sentiment_scores)
[11:19, 4/23/2024] Shivani: visualization part
[11:19, 4/23/2024] Shivani: import matplotlib.pyplot as plt

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    """
    Analyzes the sentiment of the given text using NLTK's VADER sentiment analyzer.
    Returns a dictionary containing sentiment scores.
    """
    sentiment_scores = sid.polarity_scores(text)
    return sentiment_scores

def plot_sentiment_distribution(sentiment_scores):
    """
    Plots the sentiment distribution for the given sentiment scores.
    """
    labels = list(sentiment_scores.keys())
    values = list(sentiment_scores.values())

    plt.figure(figsize=(8, 6))
    plt.bar(labels, values, color=['green', 'red', 'blue', 'orange'])
    plt.xlabel('Sentiment')
    plt.ylabel('Frequency')
    plt.title('Sentiment Distribution')
    plt.show()

def main():
    # Read quotes from the text file
    with open('quotes.txt', 'r') as file:
        quotes = file.readlines()

    # Analyze sentiment for each quote
    sentiment_scores = {'pos': 0, 'neg': 0, 'neu': 0, 'compound': 0}
    for quote in quotes:
        # Remove leading/trailing whitespaces
        quote = quote.strip()
        # Skip empty lines
        if not quote:
            continue

        # Analyze sentiment
        scores = analyze_sentiment(quote)
        sentiment_scores['pos'] += scores['pos']
        sentiment_scores['neg'] += scores['neg']
        sentiment_scores['neu'] += scores['neu']
        sentiment_scores['compound'] += scores['compound']

    # Normalize compound score to fit into the [0, 1] range
    sentiment_scores['compound'] /= len(quotes)

    print("Sentiment Scores:", sentiment_scores)

    # Plot sentiment distribution
    plot_sentiment_distribution(sentiment_scores)

if _name_ == "_main_":
    main()
